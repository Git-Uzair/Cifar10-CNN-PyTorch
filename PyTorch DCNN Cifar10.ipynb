{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65d0da5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bda8125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2070 SUPER\n"
     ]
    }
   ],
   "source": [
    "if train_on_gpu:\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cea15df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91cb065",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "998d513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_acc(pred, gt):\n",
    "    true = 0\n",
    "\n",
    "    for labels in zip(pred, gt):\n",
    "        if labels[0] == labels[1]:\n",
    "            true += 1\n",
    "\n",
    "    return (true/len(gt))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543eee4a",
   "metadata": {},
   "source": [
    "# Loading Data through PyTorch builtin function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bb8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#load data and also transform it to pytorch tensor so that can be used on model\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "#Folder should be in form ./data/cifar-10-batches-py/<all data batches here>\n",
    "\n",
    "Cfar_10_train = datasets.CIFAR10('./data/',train=True,transform=transform)\n",
    "Cfar_10_test = datasets.CIFAR10('./data/',train=False,transform=transform)\n",
    "train_data = torch.utils.data.DataLoader(Cfar_10_train,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_data = torch.utils.data.DataLoader(Cfar_10_test,\n",
    "                                          batch_size=10,\n",
    "                                          shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff50e4c",
   "metadata": {},
   "source": [
    "# Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd9b2e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv3): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=768, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=256, bias=True)\n",
      "  (drop1): Dropout(p=0.2, inplace=False)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # convolutional layer (sees 3 x32x32 image tensor) (RGB x W x H)\n",
    "        self.conv1 = nn.Conv2d(3, 96, 3, padding=1, stride=1)\n",
    "        # convolutional layer (sees 96 x16x16 tensor)\n",
    "        self.conv2 = nn.Conv2d(96, 96, 3, padding=1,stride=2)\n",
    "        # convolutional layer (sees 96 x8x8 tensor)\n",
    "        self.conv3 = nn.Conv2d(96, 192, 3, padding=1,stride=1)\n",
    "        # convolutional layer (sees 192 x4x4 tensor)\n",
    "        self.conv4 = nn.Conv2d(192, 192, 3, padding=1,stride=2)\n",
    "        \n",
    "        # linear layer (192 * 2 *2 -> 768)\n",
    "        self.fc1 = nn.Linear(192 * 2 * 2, 500)\n",
    "        # linear layer (500 -> 256)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        # linear layer (256 -> 10)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        x = F.relu(self.conv4(x))\n",
    "        \n",
    "        # flatten image input\n",
    "        x = x.view(-1, 192 * 2 * 2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x=self.drop1(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d490f105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "#testing model output for dimensions\n",
    "output = model(torch.Tensor(np.empty((1,3,32,32))).cuda().float())\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509bdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "#stochastic gradient descent for optimzing loss function\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bdfac",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615269b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.36131979969978334\n",
      "Epoch: 1 \tTesting Loss: 0.5215864757537841\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 2 \tTraining Loss: 0.32629025355339053\n",
      "Epoch: 2 \tTesting Loss: 0.5198815326213837\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 3 \tTraining Loss: 0.3253344324016571\n",
      "Epoch: 3 \tTesting Loss: 0.5171931965351104\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 4 \tTraining Loss: 0.3154613423538208\n",
      "Epoch: 4 \tTesting Loss: 0.5034890913009643\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 5 \tTraining Loss: 0.2968469530773163\n",
      "Epoch: 5 \tTesting Loss: 0.4682582497358322\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 6 \tTraining Loss: 0.2889463156223297\n",
      "Epoch: 6 \tTesting Loss: 0.46233075535297397\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 7 \tTraining Loss: 0.28042924783706663\n",
      "Epoch: 7 \tTesting Loss: 0.4600528417825699\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 8 \tTraining Loss: 0.2690238276576996\n",
      "Epoch: 8 \tTesting Loss: 0.4172309596061707\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 9 \tTraining Loss: 0.26018561191082\n",
      "Epoch: 9 \tTesting Loss: 0.40493284418582914\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 10 \tTraining Loss: 0.25234401324272154\n",
      "Epoch: 10 \tTesting Loss: 0.40625720608234406\n",
      "Epoch: 11 \tTraining Loss: 0.2451428415441513\n",
      "Epoch: 11 \tTesting Loss: 0.3775209622144699\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 12 \tTraining Loss: 0.23763267862319945\n",
      "Epoch: 12 \tTesting Loss: 0.382044864320755\n",
      "Epoch: 13 \tTraining Loss: 0.23097439589977264\n",
      "Epoch: 13 \tTesting Loss: 0.3593449609518051\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 14 \tTraining Loss: 0.22505225503921508\n",
      "Epoch: 14 \tTesting Loss: 0.35507020184993743\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 15 \tTraining Loss: 0.21922738738059996\n",
      "Epoch: 15 \tTesting Loss: 0.36284452245235443\n",
      "Epoch: 16 \tTraining Loss: 0.21386442881584167\n",
      "Epoch: 16 \tTesting Loss: 0.338603921353817\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 17 \tTraining Loss: 0.20724134261131286\n",
      "Epoch: 17 \tTesting Loss: 0.4116224303603172\n",
      "Epoch: 18 \tTraining Loss: 0.20165746283531188\n",
      "Epoch: 18 \tTesting Loss: 0.34975414152145384\n",
      "Epoch: 19 \tTraining Loss: 0.19591094531059264\n",
      "Epoch: 19 \tTesting Loss: 0.3053860516786575\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 20 \tTraining Loss: 0.1898891558408737\n",
      "Epoch: 20 \tTesting Loss: 0.36546409653425216\n",
      "Epoch: 21 \tTraining Loss: 0.18314904224395753\n",
      "Epoch: 21 \tTesting Loss: 0.30594336631298064\n",
      "Epoch: 22 \tTraining Loss: 0.17750229897022246\n",
      "Epoch: 22 \tTesting Loss: 0.32235305973291395\n",
      "Epoch: 23 \tTraining Loss: 0.1715309215927124\n",
      "Epoch: 23 \tTesting Loss: 0.3151446558356285\n",
      "Epoch: 24 \tTraining Loss: 0.1657756382036209\n",
      "Epoch: 24 \tTesting Loss: 0.2644939710080624\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 25 \tTraining Loss: 0.1601837697982788\n",
      "Epoch: 25 \tTesting Loss: 0.2643321630239487\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 26 \tTraining Loss: 0.15453549343585968\n",
      "Epoch: 26 \tTesting Loss: 0.27163293266296384\n",
      "Epoch: 27 \tTraining Loss: 0.14978672999858855\n",
      "Epoch: 27 \tTesting Loss: 0.2502027895152569\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 28 \tTraining Loss: 0.1445009900164604\n",
      "Epoch: 28 \tTesting Loss: 0.28435417966246607\n",
      "Epoch: 29 \tTraining Loss: 0.13996123448848724\n",
      "Epoch: 29 \tTesting Loss: 0.32002278437018394\n",
      "Epoch: 30 \tTraining Loss: 0.13486547402381896\n",
      "Epoch: 30 \tTesting Loss: 0.2462221753925085\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 31 \tTraining Loss: 0.13002203717947006\n",
      "Epoch: 31 \tTesting Loss: 0.2278582250535488\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 32 \tTraining Loss: 0.125655537545681\n",
      "Epoch: 32 \tTesting Loss: 0.2391533889308572\n",
      "Epoch: 33 \tTraining Loss: 0.12130745044708252\n",
      "Epoch: 33 \tTesting Loss: 0.27324688527584073\n",
      "Epoch: 34 \tTraining Loss: 0.11715985900402069\n",
      "Epoch: 34 \tTesting Loss: 0.23098399643003942\n",
      "Epoch: 35 \tTraining Loss: 0.11292264592409133\n",
      "Epoch: 35 \tTesting Loss: 0.35638944907188413\n",
      "Epoch: 36 \tTraining Loss: 0.10877286119222641\n",
      "Epoch: 36 \tTesting Loss: 0.24575253544449807\n",
      "Epoch: 37 \tTraining Loss: 0.10448944937944413\n",
      "Epoch: 37 \tTesting Loss: 0.23425248686373235\n",
      "Epoch: 38 \tTraining Loss: 0.0998230739235878\n",
      "Epoch: 38 \tTesting Loss: 0.23815628965198993\n",
      "Epoch: 39 \tTraining Loss: 0.09598375822067261\n",
      "Epoch: 39 \tTesting Loss: 0.24117270226329565\n",
      "Epoch: 40 \tTraining Loss: 0.0915526152563095\n",
      "Epoch: 40 \tTesting Loss: 0.2417065381169319\n",
      "Epoch: 41 \tTraining Loss: 0.08739083591103554\n",
      "Epoch: 41 \tTesting Loss: 0.22018898260891437\n",
      "Saving model as testing loss decreased\n",
      "Epoch: 42 \tTraining Loss: 0.08329729908823967\n",
      "Epoch: 42 \tTesting Loss: 0.26751215978339316\n",
      "Epoch: 43 \tTraining Loss: 0.07910465075016022\n",
      "Epoch: 43 \tTesting Loss: 0.39098823192864657\n",
      "Epoch: 44 \tTraining Loss: 0.07496429024219513\n",
      "Epoch: 44 \tTesting Loss: 0.24920408767983318\n",
      "Epoch: 45 \tTraining Loss: 0.07010978719472885\n",
      "Epoch: 45 \tTesting Loss: 0.22808327654749155\n",
      "Epoch: 46 \tTraining Loss: 0.06625748405933381\n",
      "Epoch: 46 \tTesting Loss: 0.27080023103952405\n",
      "Epoch: 47 \tTraining Loss: 0.06211293900370598\n",
      "Epoch: 47 \tTesting Loss: 0.24043652811571956\n",
      "Epoch: 48 \tTraining Loss: 0.057551239496469495\n",
      "Epoch: 48 \tTesting Loss: 0.3151649549692869\n",
      "Epoch: 49 \tTraining Loss: 0.05406227609395981\n",
      "Epoch: 49 \tTesting Loss: 0.30033677370101214\n"
     ]
    }
   ],
   "source": [
    "test_min = math.inf\n",
    "lossT=[]\n",
    "epoch=[]\n",
    "for epochs in range(1,50):\n",
    "    \n",
    "    training_loss = 0\n",
    "    testing_loss=0\n",
    "    model.train()\n",
    "    \n",
    "    #data in form (batch_size, RGB, H,W), label in form (Batch_size,1)\n",
    "    for data, label in train_data:\n",
    "        label = F.one_hot(label,num_classes=10)\n",
    "        if train_on_gpu:\n",
    "            data, label = data.cuda(), label.cuda().float()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #output = (batch_size,10)\n",
    "        output = model(data)\n",
    "        loss = loss_function(output,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #total loss over a batch\n",
    "        training_loss+=loss.item()*data.size(0)\n",
    "    \n",
    "    #average training loss over 1 epoch\n",
    "    training_loss=training_loss/len(train_data.dataset)    \n",
    "    lossT.append(training_loss)\n",
    "    epoch.append(epochs)\n",
    "    print('Epoch: {} \\tTraining Loss: {}'.format(epochs,training_loss))\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    for data_t, label_t in test_data:\n",
    "        label_t = F.one_hot(label_t,num_classes=10)\n",
    "        if train_on_gpu:\n",
    "            data_t, label_t = data_t.cuda(), label_t.cuda().float()\n",
    "        \n",
    "        output_t = model(data_t)\n",
    "        loss = loss_function(output_t,label_t)\n",
    "        testing_loss+=loss.item()*data.size(0)\n",
    "        \n",
    "#         for idx, pred in enumerate(output_t.max(1).indices):\n",
    "# #             print(\"Predicted: \",classes[pred])\n",
    "# #             print(\"actually: \",classes[label_t[idx].argmax()])\n",
    "#             if label_t[idx][pred]:\n",
    "                \n",
    "#                 total_correct+=1\n",
    "\n",
    "    testing_loss=testing_loss/len(test_data.dataset)\n",
    "    print('Epoch: {} \\tTesting Loss: {}'.format(epochs,testing_loss))\n",
    "    if testing_loss<test_min:\n",
    "        test_min=testing_loss\n",
    "        torch.save(model.state_dict(), './models/model+epoch{}.pth'.format(epochs))\n",
    "        print(\"Saving model as testing loss decreased\")\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32aaa0",
   "metadata": {},
   "source": [
    "# Loading best model and testing on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cae9ea45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy over Test set 71.6\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./models/model+epoch41.pth'))\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "for data_t, label_t in test_data:\n",
    "        label_t = F.one_hot(label_t,num_classes=10)\n",
    "        if train_on_gpu:\n",
    "            data_t, label_t = data_t.cuda(), label_t.cuda().float()\n",
    "        \n",
    "        output_t = model(data_t)\n",
    "        loss = loss_function(output_t,label_t)\n",
    "        testing_loss+=loss.item()*data.size(0)\n",
    "        \n",
    "        for idx, pred in enumerate(output_t.max(1).indices):\n",
    "            \n",
    "#             print(\"Predicted: \",classes[pred])\n",
    "#             print(\"actually: \",classes[label_t[idx].argmax()])\n",
    "            if label_t[idx][pred]:\n",
    "                \n",
    "                total_correct+=1\n",
    "print('Accuracy over Test set {}'.format(total_correct/len(test_data.dataset)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8f330",
   "metadata": {},
   "source": [
    "# Training Loss vs epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3601128c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch, lossT)\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
